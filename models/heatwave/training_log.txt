============================================================
EXPERIMENT 3: HEATWAVE PREDICTION (Classification)
  v2: Added XGBoost + SMOTE + new features (diurnal, precip, heat streak)
============================================================

[Data] Loading and splitting data...
   Train shape: (2917, 13), Test shape: (730, 13)
   Features: ['temp_max_lag1', 'temp_max_lag2', 'temp_max_lag3', 'temp_max_7day_avg', 'humidity', 'month_sin', 'month_cos', 'month', 'diurnal_range_lag1', 'temp_min_lag1', 'temp_min_7day_avg', 'precip_7day_sum', 'heat_streak']
   Heatwave Ratio (before SMOTE): 2.14%
   Class distribution - 0: 3569, 1: 78

[SMOTE] Oversampling minority class (heatwave)...
   After SMOTE - Train shape: (4282, 13)
   After SMOTE - Class 0: 2855, Class 1: 1427

[Experiment] Training candidate models on SMOTE-resampled data...
   > Training Logistic Regression...
     Best Params: {'classifier__C': 10.0}
     Accuracy: 0.9315 | F1: 0.3243
     Classification Report:
              precision    recall  f1-score   support

      Normal       0.99      0.94      0.96       714
    Heatwave       0.21      0.75      0.32        16

    accuracy                           0.93       730
   macro avg       0.60      0.84      0.64       730
weighted avg       0.98      0.93      0.95       730

   > Training Random Forest...
     Best Params: {'max_depth': None, 'n_estimators': 100}
     Accuracy: 0.9795 | F1: 0.5714
     Classification Report:
              precision    recall  f1-score   support

      Normal       0.99      0.99      0.99       714
    Heatwave       0.53      0.62      0.57        16

    accuracy                           0.98       730
   macro avg       0.76      0.81      0.78       730
weighted avg       0.98      0.98      0.98       730

   > Training Gradient Boosting...
     Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}
     Accuracy: 0.9822 | F1: 0.6286
     Classification Report:
              precision    recall  f1-score   support

      Normal       0.99      0.99      0.99       714
    Heatwave       0.58      0.69      0.63        16

    accuracy                           0.98       730
   macro avg       0.79      0.84      0.81       730
weighted avg       0.98      0.98      0.98       730

   > Training XGBoost...
     Best Params: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'subsample': 0.8}
     Accuracy: 0.9836 | F1: 0.6471
     Classification Report:
              precision    recall  f1-score   support

      Normal       0.99      0.99      0.99       714
    Heatwave       0.61      0.69      0.65        16

    accuracy                           0.98       730
   macro avg       0.80      0.84      0.82       730
weighted avg       0.98      0.98      0.98       730


============================================================
WINNER: XGBoost (F1 Score: 0.6471)
============================================================
Feature importance plot saved.
Plots saved to C:\Users\prabina\Code\resilience-grid-main\.claude\worktrees\trusting-wu\static\plots
Report saved to C:\Users\prabina\Code\resilience-grid-main\.claude\worktrees\trusting-wu\models\heatwave
